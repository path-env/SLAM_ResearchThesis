\section*{Introduction}
    Paramtetric filters such as EKF work on the assumption that posterior density is Gaussian paramterized by mean and covariance. In cases where the 
true density is non Gaussian, these filters fail to describe the actual posterior.In many practical applications, linear and gaussian assumptions would
not hold true, hence better approaches are required to describe the posterior density. Particle Filters are non paramteric filters which can model 
any posteriror distribution as it does not assume gaussian requiring mean and covariance. This chapter provides in-depth view of Particle Filters and
its application to SLAM.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Particle Filter}
Particle Filters manage to model the required distribution by use of set of random samples sampled from the distribution. However no a-prior information about the 
distribution is known. Hence a proposal distribution is used as a inital guess to sample particles from it and weigh it against the target distribution.
This process is repeated until the proposal distribution matches the target distribution and it requires resampling from the proposal distribution when 
necessary.The samples which weigh more are more likely to describe the target distribution. This leads to further discussion on what could be the guess 
on proposal distribution, how is it sampled, weighed ,resampled and sequentially continued to obtain the full state estimate.

\subsection{Sample}
Sampling in particle filters in based on Sequential Importance Sampling principle and Sequential Monte-Carlo methods. Samples in genral are generated in 
random from a proposal distribution. The more samples we are able to sample , the better is the approximation of the target distribution. With larger 
number of samples, Monte-Carlo methods provide equivalent representation of the target distribution and Sequential Importance Sampling approaches optimal
Bayes estimate \cite{S.Arulampalam}. In case of the Monte-Carlo approximation methods, the samples obtained are independent samples of the target distribution,
whereas in the Importance Sampling method, the samples obtained are not only independent of the target distribution but independent on the proposal distribtuion
as well. Thus the weights of each sample are not equal as in the case of Monte-Carlo approximation methods.

Let ${x^{1},x^{2},.........x^{N}}$ be list of ${N}$ particles generated from the proposal distribution ${q(x)}$.

\begin{gather} \label{Sample}
    p(x) \approx \sum_{i = 1}^{N} w^{i}\delta (x - x^{i})  
\end{gather} 
where $\delta$ is the impulse function. The above equation provides the weighted approximation of the true density given that the proposal distributuion is
similar to the target distribution and it is easy to sample from the proposal distribtuion. A typical example of a proposal distribution is gaussian.
However modeling the proposal distribution effectively for the task is discussed in later sections.

\subsection{Importance weighting}
Importance weighting is an useful outcome of Importance sampling.Each particle is weighed based on its similarity to the target distribtuion. 
More the similarity higher is the value of the weights. 
\begin{gather} \label{ImportanceWeigting}
    w \propto \frac{p(x)}{q(x)} 
\end{gather}
The weights are always normalized for reasons discussed further below.

\subsection{Sequential Importance Sampling}
Sampling and weighting discussed above are useful to estimate the state for a given instance. However in most applications it is required to estimate the state
recursively for every time instance using the previous state and the current reading. This is the core of the Sequential Importance Sampling. It involves 
sampling,weighting recursively. In the sampling step as the the sample from the motion model estimate is sufficient as the prior information untill the previous
instance is already processed.
For the ${i}^{th}$ particle:
\begin{gather} \label{SIS_Sample}
    x_{0:t}^{i} \approx q(x_{0:t}| y_{1:t}) 
\end{gather}
where ${q(x_{0:t}| y_{1:t})}$ is the posterior density of the proposal distribtuion which could be factorized as 
\begin{gather} \label{SIS_propfact}
    q(x_{0:t}| y_{1:t}) = q(x_t|x_{t-1},y_{t}) q(x_{0:t-1}| y_{1:t-1}) 
\end{gather}
In the weighting step the proposal is compared to the target density also considering its prior weight update. 
\begin{gather} \label{SIS_weight}
    w_{t}^{i} = w_{t-1}^{i} \frac{p(y_{t}|x_{t}^{i}) p(x_{t}^{i}|x_{t-1}^{i})}{q(x_t|x_{t-1},y_{t})}  
\end{gather}
With the right choice of the proposal distribtuion the weights can be derived with measurement model.
\begin{gather} \label{SIS_weightprop}
    q(x_t|x_{t-1},y_{t}) = p(x_t|x_{t-1})\\
    w_{t}^{i} = w_{t-1}^{i} * p(y_{t}|x_{t}^{i})
\end{gather}
In most cases the weights of the particles in a sample set can end up with high variance, due to which the particle with the highest weight gets sampled
repeatedly in the resampling step. This is referred to as Particle Degeneration. Hence the system's belief is stuck to one particle leading to ignorance of 
uncertainity and consequitively to divergence of the filter from the true value.

\subsection{Resample}
As the variance of the weights increase the sample set is dominated only by very few particles with high weight which results in poor state estimate. Hence
to avoid it is better to perform a resampling step where N particles are sampled from the current particle set using various stratergies. Depending on the 
stratergies used to resample various resampling techniques exists such as Systematic resampling, Random resampling, Selective resampling \dots This replaces the 
old sample set with new set of samples with equal weights. However in most cases the clarity of tolerable variance of the weights for a particle set is not clear.
It is found that Adaptive resampling provides the best criteria for resampling. This requires calculating the effective number of the particles ${N_{eff}}$
\begin{gather} \label{Neff}
N_{eff} = \frac{1}{\sum_{i=1}^{N} w_{i}^{2} } 
\end{gather}
where ${w_{i}}$ is normalized weight of the particles in the sample set and ${N}$ is the number of particles.  Resampling is performed only 
when the ${N_{eff} < N/2}$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Rao-Blackwellized Particle Filter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{gMapping-Improved RBPF}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results and Analysis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}